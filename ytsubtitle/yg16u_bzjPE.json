[
  {
    "startTime": 0.0,
    "endTime": 3.0,
    "text": "Imagine"
  },
  {
    "startTime": 5.03,
    "endTime": 7.279,
    "text": "[Music]"
  },
  {
    "startTime": 7.279,
    "endTime": 9.679,
    "text": "you're watching a runaway trolley"
  },
  {
    "startTime": 9.679,
    "endTime": 11.92,
    "text": "barreling down the tracks straight"
  },
  {
    "startTime": 11.92,
    "endTime": 15.759,
    "text": "towards five workers who can't escape."
  },
  {
    "startTime": 15.759,
    "endTime": 17.52,
    "text": "You happen to be standing next to a"
  },
  {
    "startTime": 17.52,
    "endTime": 19.92,
    "text": "switch that will divert the trolley onto"
  },
  {
    "startTime": 19.92,
    "endTime": 23.119,
    "text": "a second track. Here's the problem. That"
  },
  {
    "startTime": 23.119,
    "endTime": 26.16,
    "text": "track has a worker on it, too, but just"
  },
  {
    "startTime": 26.16,
    "endTime": 27.84,
    "text": "one."
  },
  {
    "startTime": 27.84,
    "endTime": 30.32,
    "text": "What do you do? Do you sacrifice one"
  },
  {
    "startTime": 30.32,
    "endTime": 32.88,
    "text": "person to save five?"
  },
  {
    "startTime": 32.88,
    "endTime": 35.84,
    "text": "This is the trolley problem, a version"
  },
  {
    "startTime": 35.84,
    "endTime": 38.079,
    "text": "of an ethical dilemma that philosopher"
  },
  {
    "startTime": 38.079,
    "endTime": 41.84,
    "text": "Philip of Foot devised in 1967."
  },
  {
    "startTime": 41.84,
    "endTime": 43.84,
    "text": "It's popular because it forces us to"
  },
  {
    "startTime": 43.84,
    "endTime": 46.16,
    "text": "think about how to choose when there are"
  },
  {
    "startTime": 46.16,
    "endTime": 48.8,
    "text": "no good choices. Do we pick the action"
  },
  {
    "startTime": 48.8,
    "endTime": 51.039,
    "text": "with the best outcome or stick to a"
  },
  {
    "startTime": 51.039,
    "endTime": 53.44,
    "text": "moral code that prohibits causing"
  },
  {
    "startTime": 53.44,
    "endTime": 56.64,
    "text": "someone's death? In one survey, about"
  },
  {
    "startTime": 56.64,
    "endTime": 59.359,
    "text": "90% of respondents said that it's okay"
  },
  {
    "startTime": 59.359,
    "endTime": 61.76,
    "text": "to flip the switch, letting one worker"
  },
  {
    "startTime": 61.76,
    "endTime": 65.198,
    "text": "die to save five. And other studies,"
  },
  {
    "startTime": 65.199,
    "endTime": 67.439,
    "text": "including a virtual reality simulation"
  },
  {
    "startTime": 67.439,
    "endTime": 69.439,
    "text": "of the dilemma, have found similar"
  },
  {
    "startTime": 69.439,
    "endTime": 72.4,
    "text": "results. These judgments are consistent"
  },
  {
    "startTime": 72.4,
    "endTime": 74.479,
    "text": "with the philosophical principle of"
  },
  {
    "startTime": 74.479,
    "endTime": 76.88,
    "text": "utilitarianism, which argues that the"
  },
  {
    "startTime": 76.88,
    "endTime": 79.28,
    "text": "morally correct decision is the one that"
  },
  {
    "startTime": 79.28,
    "endTime": 81.6,
    "text": "maximizes well-being for the greatest"
  },
  {
    "startTime": 81.6,
    "endTime": 84.159,
    "text": "number of people. The five lives"
  },
  {
    "startTime": 84.159,
    "endTime": 86.799,
    "text": "outweigh one, even if achieving that"
  },
  {
    "startTime": 86.799,
    "endTime": 89.439,
    "text": "outcome requires condemning someone to"
  },
  {
    "startTime": 89.439,
    "endTime": 92.0,
    "text": "death. But people don't always take the"
  },
  {
    "startTime": 92.0,
    "endTime": 94.32,
    "text": "utilitarian view, which we can see by"
  },
  {
    "startTime": 94.32,
    "endTime": 97.2,
    "text": "changing the trolley problem a bit. This"
  },
  {
    "startTime": 97.2,
    "endTime": 99.439,
    "text": "time you're standing on a bridge over"
  },
  {
    "startTime": 99.439,
    "endTime": 101.6,
    "text": "the track as the runaway trolley"
  },
  {
    "startTime": 101.6,
    "endTime": 104.56,
    "text": "approaches. Now there's no second track,"
  },
  {
    "startTime": 104.56,
    "endTime": 107.04,
    "text": "but there is a very large man on the"
  },
  {
    "startTime": 107.04,
    "endTime": 109.439,
    "text": "bridge next to you. If you push him"
  },
  {
    "startTime": 109.439,
    "endTime": 112.399,
    "text": "over, his body will stop the trolley."
  },
  {
    "startTime": 112.399,
    "endTime": 115.84,
    "text": "saving the five workers, but he'll die."
  },
  {
    "startTime": 115.84,
    "endTime": 118.399,
    "text": "To utilitarians, the decision is exactly"
  },
  {
    "startTime": 118.399,
    "endTime": 121.759,
    "text": "the same. Lose one life to save five."
  },
  {
    "startTime": 121.759,
    "endTime": 124.24,
    "text": "But in this case, only about 10% of"
  },
  {
    "startTime": 124.24,
    "endTime": 126.56,
    "text": "people say that it's okay to throw the"
  },
  {
    "startTime": 126.56,
    "endTime": 129.44,
    "text": "man onto the tracks. Our instincts tell"
  },
  {
    "startTime": 129.44,
    "endTime": 131.44,
    "text": "us that deliberately causing someone's"
  },
  {
    "startTime": 131.44,
    "endTime": 133.84,
    "text": "death is different than allowing them to"
  },
  {
    "startTime": 133.84,
    "endTime": 137.2,
    "text": "die as collateral damage. It just feels"
  },
  {
    "startTime": 137.2,
    "endTime": 139.12,
    "text": "wrong for reasons that are hard to"
  },
  {
    "startTime": 139.12,
    "endTime": 140.72,
    "text": "explain."
  },
  {
    "startTime": 140.72,
    "endTime": 142.64,
    "text": "This intersection between ethics and"
  },
  {
    "startTime": 142.64,
    "endTime": 144.8,
    "text": "psychology is what's so interesting"
  },
  {
    "startTime": 144.8,
    "endTime": 146.959,
    "text": "about the trolley problem. The dilemma"
  },
  {
    "startTime": 146.959,
    "endTime": 149.52,
    "text": "and its many variations reveal that what"
  },
  {
    "startTime": 149.52,
    "endTime": 151.68,
    "text": "we think is right or wrong depends on"
  },
  {
    "startTime": 151.68,
    "endTime": 154.239,
    "text": "factors other than a logical weighing of"
  },
  {
    "startTime": 154.239,
    "endTime": 157.76,
    "text": "the pros and cons. For example, men are"
  },
  {
    "startTime": 157.76,
    "endTime": 159.84,
    "text": "more likely than women to say it's okay"
  },
  {
    "startTime": 159.84,
    "endTime": 162.8,
    "text": "to push the man over the bridge. So are"
  },
  {
    "startTime": 162.8,
    "endTime": 164.879,
    "text": "people who watch a comedy clip before"
  },
  {
    "startTime": 164.879,
    "endTime": 167.44,
    "text": "doing the thought experiment. And in one"
  },
  {
    "startTime": 167.44,
    "endTime": 170.0,
    "text": "virtual reality study, people were more"
  },
  {
    "startTime": 170.0,
    "endTime": 173.12,
    "text": "willing to sacrifice men than women."
  },
  {
    "startTime": 173.12,
    "endTime": 174.64,
    "text": "Researchers have studied the brain"
  },
  {
    "startTime": 174.64,
    "endTime": 176.8,
    "text": "activity of people thinking through the"
  },
  {
    "startTime": 176.8,
    "endTime": 179.68,
    "text": "classic and bridge versions. Both"
  },
  {
    "startTime": 179.68,
    "endTime": 181.92,
    "text": "scenarios activate areas of the brain"
  },
  {
    "startTime": 181.92,
    "endTime": 184.319,
    "text": "involved in conscious decision-m and"
  },
  {
    "startTime": 184.319,
    "endTime": 186.319,
    "text": "emotional responses."
  },
  {
    "startTime": 186.319,
    "endTime": 188.4,
    "text": "But in the bridge version, the emotional"
  },
  {
    "startTime": 188.4,
    "endTime": 191.44,
    "text": "response is much stronger. So is"
  },
  {
    "startTime": 191.44,
    "endTime": 193.28,
    "text": "activity in an area of the brain"
  },
  {
    "startTime": 193.28,
    "endTime": 195.36,
    "text": "associated with processing internal"
  },
  {
    "startTime": 195.36,
    "endTime": 198.239,
    "text": "conflict. Why the difference? One"
  },
  {
    "startTime": 198.239,
    "endTime": 200.319,
    "text": "explanation is that pushing someone to"
  },
  {
    "startTime": 200.319,
    "endTime": 202.64,
    "text": "their death feels more personal,"
  },
  {
    "startTime": 202.64,
    "endTime": 205.2,
    "text": "activating an emotional aversion to"
  },
  {
    "startTime": 205.2,
    "endTime": 207.44,
    "text": "killing another person. But we feel"
  },
  {
    "startTime": 207.44,
    "endTime": 209.44,
    "text": "conflicted because we know it's still"
  },
  {
    "startTime": 209.44,
    "endTime": 211.76,
    "text": "the logical choice."
  },
  {
    "startTime": 211.76,
    "endTime": 214.319,
    "text": "Trology has been criticized by some"
  },
  {
    "startTime": 214.319,
    "endTime": 216.959,
    "text": "philosophers and psychologists. They"
  },
  {
    "startTime": 216.959,
    "endTime": 218.879,
    "text": "argue that it doesn't reveal anything"
  },
  {
    "startTime": 218.879,
    "endTime": 221.36,
    "text": "because its premise is so unrealistic"
  },
  {
    "startTime": 221.36,
    "endTime": 223.76,
    "text": "that study participants don't take it"
  },
  {
    "startTime": 223.76,
    "endTime": 225.28,
    "text": "seriously."
  },
  {
    "startTime": 225.28,
    "endTime": 227.2,
    "text": "But new technology is making this kind"
  },
  {
    "startTime": 227.2,
    "endTime": 229.76,
    "text": "of ethical analysis more important than"
  },
  {
    "startTime": 229.76,
    "endTime": 232.879,
    "text": "ever. For example, driverless cars may"
  },
  {
    "startTime": 232.879,
    "endTime": 235.04,
    "text": "have to handle choices like causing a"
  },
  {
    "startTime": 235.04,
    "endTime": 237.84,
    "text": "small accident to prevent a larger one."
  },
  {
    "startTime": 237.84,
    "endTime": 239.76,
    "text": "Meanwhile, governments are researching"
  },
  {
    "startTime": 239.76,
    "endTime": 242.159,
    "text": "autonomous military drones that could"
  },
  {
    "startTime": 242.159,
    "endTime": 244.159,
    "text": "wind up making decisions of whether"
  },
  {
    "startTime": 244.159,
    "endTime": 246.4,
    "text": "they'll risk civilian casualties to"
  },
  {
    "startTime": 246.4,
    "endTime": 249.76,
    "text": "attack a high value target. If we want"
  },
  {
    "startTime": 249.76,
    "endTime": 252.159,
    "text": "these actions to be ethical, we have to"
  },
  {
    "startTime": 252.159,
    "endTime": 255.04,
    "text": "decide in advance how to value human"
  },
  {
    "startTime": 255.04,
    "endTime": 257.84,
    "text": "life and judge the greater good. So"
  },
  {
    "startTime": 257.84,
    "endTime": 260.239,
    "text": "researchers who study autonomous systems"
  },
  {
    "startTime": 260.239,
    "endTime": 262.56,
    "text": "are collaborating with philosophers to"
  },
  {
    "startTime": 262.56,
    "endTime": 264.639,
    "text": "address the complex problem of"
  },
  {
    "startTime": 264.639,
    "endTime": 268.16,
    "text": "programming ethics into machines. Which"
  },
  {
    "startTime": 268.16,
    "endTime": 270.24,
    "text": "goes to show that even hypothetical"
  },
  {
    "startTime": 270.24,
    "endTime": 272.8,
    "text": "dilemmas can wind up on a collision"
  },
  {
    "startTime": 272.8,
    "endTime": 277.24,
    "text": "course with the real world."
  },
  {
    "startTime": 283.28,
    "endTime": 286.41,
    "text": "[Music]"
  }
]